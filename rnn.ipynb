{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Assuming your CSV file is named \"data.csv\"\n",
    "training_data = pd.read_csv(\"../gym-unbalanced-disk/disc-benchmark-files/training-val-test-data.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data for ANN\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "ulist = training_data.iloc[:, 0].tolist()[1:]   # Input voltage\n",
    "ylist = training_data.iloc[:, 1].tolist()[1:]  # Output angle\n",
    "\n",
    "# Convert elements to floats\n",
    "ulist = [float(val) for val in ulist]\n",
    "ylist = [float(val) for val in ylist]\n",
    "\n",
    "##########\n",
    "na, nb = 5,5 # How many past data is used \n",
    "##########\n",
    "\n",
    "def create_IO_data(u,y,na,nb):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for k in range(max(na,nb), len(y)):\n",
    "        X.append(np.concatenate([u[k-nb:k],y[k-na:k]]))\n",
    "        Y.append(y[k])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "Xdata, Ydata = create_IO_data(ulist, ylist, na, nb)\n",
    "\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xdata, Ydata) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vddal\\AppData\\Local\\Temp\\ipykernel_52240\\2763831793.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  U_RNN = torch.tensor(U_RNN, dtype=torch.float64)\n",
      "C:\\Users\\vddal\\AppData\\Local\\Temp\\ipykernel_52240\\2763831793.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_RNN = torch.tensor(Y_RNN, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Training Data for RNN\n",
    "import torch\n",
    "\n",
    "def make_OE_data(udata, ydata, nf=100):\n",
    "    U = [] \n",
    "    Y = [] \n",
    "    for k in range(nf,len(udata)+1):\n",
    "        U.append(udata[k-nf:k]) #a)\n",
    "        Y.append(ydata[k-nf:k]) #a)\n",
    "    return np.array(U), np.array(Y)\n",
    "\n",
    "nfuture = 20 # Capturing Temporal Dependencies\n",
    "convert = lambda x: [torch.tensor(xi,dtype=torch.float64) for xi in x]\n",
    "U_RNN, Y_RNN = convert(make_OE_data(ulist, ylist, nf=nfuture))\n",
    "\n",
    "U_RNN = torch.tensor(U_RNN, dtype=torch.float64)\n",
    "Y_RNN = torch.tensor(Y_RNN, dtype=torch.float64)\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(U_RNN))\n",
    "\n",
    "# Split data into training and validation sets\n",
    "Utrain, Ytrain_RNN = U_RNN[:split_index], Y_RNN[:split_index]\n",
    "Uval, Yval_RNN = U_RNN[split_index:], Y_RNN[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, Validation NRMS=47.31%, Train NRMS=42.26%\n",
      "epoch=1, Validation NRMS=45.35%, Train NRMS=40.79%\n",
      "epoch=2, Validation NRMS=44.85%, Train NRMS=40.31%\n",
      "epoch=3, Validation NRMS=45.02%, Train NRMS=40.52%\n",
      "epoch=4, Validation NRMS=44.85%, Train NRMS=40.37%\n",
      "epoch=5, Validation NRMS=44.86%, Train NRMS=40.27%\n",
      "epoch=6, Validation NRMS=44.88%, Train NRMS=40.33%\n",
      "epoch=7, Validation NRMS=44.79%, Train NRMS=40.23%\n",
      "epoch=8, Validation NRMS=44.79%, Train NRMS=40.25%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 62\u001b[0m\n\u001b[0;32m     58\u001b[0m     Loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(residual[:,n_burn:]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mLoss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m#d)\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \u001b[38;5;66;03m#monitor\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vddal\\anaconda3\\envs\\experiments\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vddal\\anaconda3\\envs\\experiments\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = 1\n",
    "        self.output_size = 1\n",
    "        net = lambda n_in,n_out: nn.Sequential(\n",
    "            nn.Linear(n_in,20), \\\n",
    "            nn.Sigmoid(), \\\n",
    "            nn.Linear(20,hidden_size), \\\n",
    "            nn.Sigmoid(), \\\n",
    "            nn.Linear(hidden_size,n_out)).double()\n",
    "        self.h2h = net(self.input_size + hidden_size, self.hidden_size) \n",
    "        self.h2o = net(self.input_size + hidden_size, self.output_size) \n",
    "                                                                        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #input.shape == (N_batch, N_time)\n",
    "        hidden = torch.zeros(inputs.shape[0], self.hidden_size, dtype=torch.float64) #c)\n",
    "        outputs = [] #c)\n",
    "        for i in range(inputs.shape[1]): #c)\n",
    "            u = inputs[:,i] #shape = (N_batch,) #c)\n",
    "            combined = torch.cat((hidden, u[:,None]), dim=1) #c) #shape = (N_batch,hidden_size+1)\n",
    "            outputs.append(self.h2o(combined)[:,0]) #c)\n",
    "            hidden = self.h2h(combined) #c)\n",
    "        return torch.stack(outputs,dim=1) #c)\n",
    "   \n",
    "\n",
    "# Training\n",
    "n_hidden_nodes = 50\n",
    "epochs = 60\n",
    "n_burn = 0#\n",
    "batch_size = 64 #Xtrain.shape[1]\n",
    "lr = 0.001\n",
    "\n",
    "model = RNN(n_hidden_nodes) \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr) \n",
    "Utrain, Uval, Ytrain_RNN, Yval_RNN = [torch.as_tensor(x) for x in [Utrain, Uval, Ytrain_RNN, Yval_RNN]] \n",
    "\n",
    "ids = np.arange(len(Utrain),dtype=int) \n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(ids) #inspace shuffle of the ids of the training set to select a random subset \n",
    "    for i in range(0,len(Utrain),batch_size):\n",
    "        ids_now = ids[i:i+batch_size] #the ids of the current batch\n",
    "        Uin = Utrain[ids_now] #d)\n",
    "        Y_real = Ytrain_RNN[ids_now] #d)\n",
    "\n",
    "        Y_predict = model.forward(inputs=Uin)\n",
    "\n",
    "\n",
    "        residual = Y_real - Y_predict #d)\n",
    "        Loss = torch.mean(residual[:,n_burn:]**2) #d)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()  #d)\n",
    "        Loss.backward()  #d)\n",
    "        optimizer.step()  #d)\n",
    "\n",
    "    \n",
    "    with torch.no_grad(): #monitor\n",
    "        Loss_val = torch.mean((model(inputs=Uval)[:,n_burn:] - Yval_RNN[:,n_burn:])**2)**0.5\n",
    "        Loss_train = torch.mean((model(inputs=Utrain)[:,n_burn:] - Ytrain_RNN[:,n_burn:])**2)**0.5\n",
    "        print(f'epoch={epoch}, Validation NRMS={Loss_val.item():.2%}, Train NRMS={Loss_train.item():.2%}')\n",
    "\n",
    "        val_losses.append(Loss_val.item())\n",
    "        train_losses.append(Loss_train.item())\n",
    "\n",
    "        if Loss_val < best_val_loss:\n",
    "            best_val_loss = Loss_val\n",
    "            best_val_epoch = epoch\n",
    "            #torch.save(model.state_dict(), f\"best_model.pth\") #saving the model too much was giving issues\n",
    "            \n",
    "\n",
    "torch.save(model.state_dict(), f\"rnn_model.pth{nfuture}nfuture\")\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(range(epochs), [loss for loss in train_losses], label='Training Loss')\n",
    "plt.plot(range(epochs), [loss for loss in val_losses], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (%)')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Printing best validation and epoch\n",
    "# print(\"Lowest Validation:\", best_val_loss)\n",
    "# print(\"Epoch\", best_val_epoch) # We can use this to retrain the model with this number of epochs\n",
    "\n",
    "# #model = Network(Xtrain.shape[1], n_hidden_nodes)\n",
    "# #model.load_state_dict(torch.load(\"final_model.pth\"))\n",
    "\n",
    "# model = RNN(n_hidden_nodes) \n",
    "# model.load_state_dict(torch.load(\"rnn_model.pth\"))\n",
    "\n",
    "\n",
    "# ystar = model(Uval)\n",
    "# print(Uval.shape)\n",
    "# print(ystar.shape)\n",
    "\n",
    "# print('Prediction:', float(ystar[0]))\n",
    "# print('Solution', float(Yval_RNN[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train prediction errors:\n",
      "RMS: 0.6003465642386993 radians\n",
      "RMS: 34.39732437605703 degrees\n",
      "NRMS: 125.57851701694163 %\n"
     ]
    }
   ],
   "source": [
    "out = np.load('../gym-unbalanced-disk/disc-benchmark-files/training-val-test-data.npz')\n",
    "th_train = out['th'] #th[0],th[1],th[2],th[3],...\n",
    "u_train = out['u'] #u[0],u[1],u[2],u[3],...\n",
    "\n",
    "# data = np.load('test-prediction-submission-file.npz')\n",
    "data = np.load('../gym-unbalanced-disk/disc-benchmark-files/hidden-test-prediction-submission-file.npz')\n",
    "upast_test = data['upast'] #N by u[k-15],u[k-14],...,u[k-1]\n",
    "thpast_test = data['thpast'] #N by y[k-15],y[k-14],...,y[k-1]\n",
    "# thpred = data['thnow'] #all zeros\n",
    "\n",
    "#Xtrain, Ytrain = create_IO_data(u_train, th_train, na, nb)\n",
    "#Xtrain = torch.tensor(Xtrain, dtype=torch.float64)\n",
    "\n",
    "#reg = Network(Xtrain.shape[1], n_hidden_nodes)\n",
    "#reg.load_state_dict(torch.load(\"final_model.pth\"))\n",
    "\n",
    "nfuture = 5 #We only want the next output\n",
    "convert = lambda x: [torch.tensor(xi,dtype=torch.float64) for xi in x]\n",
    "U_RNN, Y_RNN = convert(make_OE_data(u_train, th_train, nf=nfuture))\n",
    "\n",
    "# U_RNN = torch.tensor(U_RNN, dtype=torch.float64)\n",
    "# Y_RNN = torch.tensor(Y_RNN, dtype=torch.float64)\n",
    "\n",
    "\n",
    "reg = RNN(n_hidden_nodes) \n",
    "reg.load_state_dict(torch.load(\"rnn_model.pth\"))\n",
    "\n",
    "Ytrain_pred = reg(U_RNN)\n",
    "\n",
    "Ytrain_pred = Ytrain_pred.detach().numpy()\n",
    "Y_RNN = Y_RNN.detach().numpy()\n",
    "\n",
    "\n",
    "print('train prediction errors:')\n",
    "print('RMS:', np.mean((Ytrain_pred-Y_RNN)**2)**0.5,'radians')\n",
    "print('RMS:', np.mean((Ytrain_pred-Y_RNN)**2)**0.5/(2*np.pi)*360,'degrees')\n",
    "print('NRMS:', np.mean((Ytrain_pred-Y_RNN)**2)**0.5/Ytrain.std()*100,'%')\n",
    "\n",
    "#only select the ones that are used in the example\n",
    "Xtest = np.concatenate([upast_test[:,15-nb:], thpast_test[:,15-na:]],axis=1)\n",
    "Xtest = torch.tensor(Xtest, dtype=torch.float64)\n",
    "\n",
    "Ypredict = reg(Xtest)\n",
    "Ypredict = Ypredict.detach().numpy()\n",
    "\n",
    "assert len(Ypredict)==len(upast_test), 'number of samples changed!!'\n",
    "\n",
    "np.savez('../gym-unbalanced-disk/disc-benchmark-files/hidden-test-prediction-example-submission-file.npz', upast=upast_test, thpast=thpast_test, thnow=Ypredict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train prediction errors:\n",
      "RMS: 0.6223071702316233 radians\n",
      "RMS: 35.655574415001276 degrees\n",
      "NRMS: 130.17216424948955 %\n",
      "1\n",
      "train simulation errors:\n",
      "RMS: 0.08769937643212412 radians\n",
      "RMS: 5.024804135489792 degrees\n",
      "NRMS: 18.295962516110276 %\n"
     ]
    }
   ],
   "source": [
    "# Simulation\n",
    "out = np.load('../gym-unbalanced-disk/disc-benchmark-files/training-val-test-data.npz')\n",
    "th_train = out['th'] #th[0],th[1],th[2],th[3],...\n",
    "u_train = out['u'] #u[0],u[1],u[2],u[3],...\n",
    "\n",
    "data = np.load('../gym-unbalanced-disk/disc-benchmark-files/hidden-test-simulation-submission-file.npz')\n",
    "u_test = data['u']\n",
    "th_test = data['th'] #only the first 50 values are filled the rest are zeros\n",
    "\n",
    "\n",
    "#Xtrain, Ytrain = create_IO_data(u_train, th_train, na, nb)\n",
    "#Xtrain = torch.tensor(Xtrain, dtype=torch.float64)\n",
    "#reg = Network(Xtrain.shape[1], n_hidden_nodes)\n",
    "#reg.load_state_dict(torch.load(\"final_model.pth\"))\n",
    "\n",
    "nfuture = 1 #We only want the next output\n",
    "convert = lambda x: [torch.tensor(xi,dtype=torch.float64) for xi in x]\n",
    "U_RNN, Y_RNN = convert(make_OE_data(u_train, th_train, nf=nfuture))\n",
    "\n",
    "# U_RNN = torch.tensor(U_RNN, dtype=torch.float64)\n",
    "# Y_RNN = torch.tensor(Y_RNN, dtype=torch.float64)\n",
    "\n",
    "\n",
    "reg = RNN(n_hidden_nodes) \n",
    "reg.load_state_dict(torch.load(\"rnn_model.pth\"))\n",
    "\n",
    "Ytrain_pred = reg(U_RNN)\n",
    "\n",
    "Ytrain_pred = Ytrain_pred.detach().numpy()\n",
    "Y_RNN = Y_RNN.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "print('train prediction errors:')\n",
    "print('RMS:', np.mean((Ytrain_pred-Y_RNN)**2)**0.5,'radians')\n",
    "print('RMS:', np.mean((Ytrain_pred-Y_RNN)**2)**0.5/(2*np.pi)*360,'degrees')\n",
    "print('NRMS:', np.mean((Ytrain_pred-Y_RNN)**2)**0.5/Ytrain.std()*100,'%')\n",
    "\n",
    "\n",
    "def simulation_IO_model(f, ulist, ylist, skip=50):\n",
    "\n",
    "    upast = ulist[skip-na:skip].tolist() #good initialization\n",
    "    ypast = ylist[skip-nb:skip].tolist()\n",
    "    Y = ylist[:skip].tolist()\n",
    "    for u in ulist[skip:]:\n",
    "        print(\"1\")\n",
    "        upast_np = np.array([v.detach().numpy() if isinstance(v, torch.Tensor) else v for v in upast])\n",
    "        ypast_np = np.array([v.detach().numpy() if isinstance(v, torch.Tensor) else v for v in ypast])\n",
    "        x = np.concatenate([upast_np, ypast_np], axis=0)\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.float64)\n",
    "        ypred = f(x)\n",
    "        Y.append(ypred[0].detach().numpy().item()) # original: Y.append(ypred.detach().numpy().item()) \n",
    "        upast.append(u)\n",
    "        upast.pop(0)\n",
    "        ypast.append(ypred)\n",
    "        ypast.pop(0)\n",
    "    return np.array(Y)\n",
    "\n",
    "skip = len(u_train) - 1 # This way we only gets one output per sequence of inputs\n",
    "# skip = max(na,nb)\n",
    "\n",
    "th_train_sim = simulation_IO_model(lambda x: reg(x[None,:])[0], u_train, th_train, skip=skip)\n",
    "print('train simulation errors:')\n",
    "print('RMS:', np.mean((th_train_sim[skip:]-th_train[skip:])**2)**0.5,'radians')\n",
    "print('RMS:', np.mean((th_train_sim[skip:]-th_train[skip:])**2)**0.5/(2*np.pi)*360,'degrees')\n",
    "print('NRMS:', np.mean((th_train_sim[skip:]-th_train[skip:])**2)**0.5/th_train.std()*100,'%')\n",
    "\n",
    "\n",
    "th_test_sim = simulation_IO_model(lambda x: reg(x[None,:])[0], u_test, th_test, skip=skip)\n",
    "\n",
    "assert len(th_test_sim)==len(th_test)\n",
    "np.savez('../gym-unbalanced-disk/disc-benchmark-files/hidden-test-simulation-example-submission-file.npz', th=th_test_sim, u=u_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise Set 3 Deep Learning for S&C.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
